{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GBXhZkoa3_K8vf8sCoRPHIliH4jwea69",
      "authorship_tag": "ABX9TyNB6hYkpvqno1optyIyBxoO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import vgg19, VGG19_Weights\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/test image\"\n",
        "OUTPUT_DIR = \"./vgg19_encodings\"\n",
        "MAX_PROPOSALS = 50\n",
        "MIN_PROP_AREA = 5000\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def build_vgg19_fc2(device):\n",
        "    weights = VGG19_Weights.DEFAULT\n",
        "    vgg = vgg19(weights=weights)\n",
        "    vgg.eval().to(device)\n",
        "    feature_extractor = nn.Sequential(\n",
        "        vgg.features,\n",
        "        nn.Flatten(start_dim=1),\n",
        "        *list(vgg.classifier.children())[:6]\n",
        "    ).to(device)\n",
        "    feature_extractor.eval()\n",
        "    transform = weights.transforms()\n",
        "    return feature_extractor, transform\n",
        "\n",
        "def selective_search_proposals(img_bgr):\n",
        "    try:\n",
        "        ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
        "        ss.setBaseImage(img_bgr)\n",
        "        ss.switchToSelectiveSearchFast()\n",
        "        rects = ss.process()\n",
        "        seen, unique = set(), []\n",
        "        for (x, y, w, h) in rects:\n",
        "            if (x, y, w, h) not in seen:\n",
        "                seen.add((x, y, w, h))\n",
        "                unique.append((x, y, w, h))\n",
        "        return unique\n",
        "    except Exception as e:\n",
        "        print(\"Selective Search not available, using sliding windows.\", e)\n",
        "        return []\n",
        "\n",
        "def sliding_window_proposals(img_shape, step_ratio=0.2, window_sizes=((224,224),(256,256),(180,180))):\n",
        "    h, w = img_shape[:2]\n",
        "    rects = []\n",
        "    for win_w, win_h in window_sizes:\n",
        "        step_x = max(8, int(win_w * step_ratio))\n",
        "        step_y = max(8, int(win_h * step_ratio))\n",
        "        for y in range(0, h - win_h + 1, step_y):\n",
        "            for x in range(0, w - win_w + 1, step_x):\n",
        "                rects.append((x, y, win_w, win_h))\n",
        "    return rects\n",
        "\n",
        "def iou(boxA, boxB):\n",
        "    xA, yA = max(boxA[0], boxB[0]), max(boxA[1], boxB[1])\n",
        "    xB, yB = min(boxA[0]+boxA[2], boxB[0]+boxB[2]), min(boxA[1]+boxA[3], boxB[1]+boxB[3])\n",
        "    inter = max(0, xB-xA) * max(0, yB-yA)\n",
        "    union = boxA[2]*boxA[3] + boxB[2]*boxB[3] - inter\n",
        "    return inter / union if union > 0 else 0.0\n",
        "\n",
        "def filter_rects(rects, shape, max_props, min_area, iou_thresh=0.95):\n",
        "    rects = [r for r in rects if r[2]*r[3] >= min_area]\n",
        "    rects.sort(key=lambda r: r[2]*r[3], reverse=True)\n",
        "    selected = []\n",
        "    for r in rects:\n",
        "        if all(iou(r, s) < iou_thresh for s in selected):\n",
        "            x, y, w, h = r\n",
        "            x, y = max(0, x), max(0, y)\n",
        "            w, h = min(w, shape[1]-x), min(h, shape[0]-y)\n",
        "            if w > 0 and h > 0:\n",
        "                selected.append((x, y, w, h))\n",
        "        if len(selected) >= max_props:\n",
        "            break\n",
        "    return selected\n",
        "\n",
        "def encode_image_regions(image_path, model, transform, device):\n",
        "    img_bgr = cv2.imread(image_path)\n",
        "    if img_bgr is None:\n",
        "        raise FileNotFoundError(f\"Cannot read image: {image_path}\")\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    rects = selective_search_proposals(img_bgr)\n",
        "    if not rects:\n",
        "        rects = sliding_window_proposals(img_rgb.shape)\n",
        "    rects = filter_rects(rects, img_rgb.shape, MAX_PROPOSALS, MIN_PROP_AREA)\n",
        "\n",
        "    if len(rects) == 0:\n",
        "        return np.zeros((0,4096)), pd.DataFrame(columns=[\"x\",\"y\",\"w\",\"h\"])\n",
        "\n",
        "    tensors, meta = [], []\n",
        "    for (x,y,w,h) in rects:\n",
        "        crop = Image.fromarray(img_rgb[y:y+h, x:x+w])\n",
        "        tensors.append(transform(crop))\n",
        "        meta.append((x,y,w,h))\n",
        "\n",
        "    xs = torch.stack(tensors).to(device)\n",
        "    with torch.no_grad():\n",
        "        feats = []\n",
        "        for i in range(0, len(xs), 16):\n",
        "            out = model(xs[i:i+16])\n",
        "            feats.append(out.cpu().numpy())\n",
        "        feats = np.vstack(feats)\n",
        "\n",
        "    df_meta = pd.DataFrame(meta, columns=[\"x\",\"y\",\"w\",\"h\"])\n",
        "    return feats, df_meta\n",
        "\n",
        "def find_images(folder):\n",
        "    exts = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tiff\"}\n",
        "    images = []\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for f in files:\n",
        "            if os.path.splitext(f.lower())[1] in exts:\n",
        "                images.append(os.path.join(root, f))\n",
        "    return sorted(images)\n",
        "\n",
        "def main():\n",
        "    device = torch.device(DEVICE)\n",
        "    model, transform = build_vgg19_fc2(device)\n",
        "    images = find_images(DATA_DIR)\n",
        "\n",
        "    if len(images) == 0:\n",
        "        print(\" No images found in folder:\", DATA_DIR)\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(images)} image(s). Device: {device}\")\n",
        "    summary_rows = []\n",
        "\n",
        "    for im_path in tqdm(images, desc=\"Encoding images\"):\n",
        "        try:\n",
        "            feats, df_meta = encode_image_regions(im_path, model, transform, device)\n",
        "            base = os.path.splitext(os.path.basename(im_path))[0]\n",
        "            np.save(os.path.join(OUTPUT_DIR, f\"{base}_proposals_feats.npy\"), feats)\n",
        "            df_meta.to_csv(os.path.join(OUTPUT_DIR, f\"{base}_proposals_meta.csv\"), index=False)\n",
        "            summary_rows.append({\n",
        "                \"image\": im_path,\n",
        "                \"n_proposals\": len(df_meta),\n",
        "                \"feat_file\": f\"{base}_proposals_feats.npy\",\n",
        "                \"meta_file\": f\"{base}_proposals_meta.csv\"\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {im_path}: {e}\")\n",
        "\n",
        "    pd.DataFrame(summary_rows).to_csv(os.path.join(OUTPUT_DIR, \"summary.csv\"), index=False)\n",
        "    print(\"\\n Done. Encodings saved to:\", OUTPUT_DIR)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "QauOrr6HUyJV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}